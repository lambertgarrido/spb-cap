table, th, td {
  border: 1px solid black;
  border-collapse: collapse;
}

## INTRODUCTION

In this project, the monthly housing cost is predicted by applying several supervised machine learning models available in the Python scikit-learn library. A potential home buyer could benefit from this machine learning application by providing the user a cost estimate of a property before closing the deal. Government agencies could use this application to identify homes in financial distress in a given region, thereby influencing their policy decisions.

## DATA
The data set used is called the Housing Affordability Data System (HADS) which consists of individual datasets spanning the years 1985 to 2013. The data sets are available for download here: [American Housing Survey: Housing Affordability Data System](https://www.huduser.gov/portal/datasets/hads/hads.html). The HADS data are sourced from the American Housing Survey (AHS) national sample microdata and the AHS metropolitan sample microdata. Therefore, more details can be obtained by referring to the AHS data. Each row in the data is an observation of a housing unit. The features fall under 4 categories:

* Cost measures: Utility costs, mortgage payments, HOA fees
* Housing unit characteristics: number of bedrooms, year built, location, structure type
* Household characteristics: income, number of people, rent/owner status
* Local market conditions: median income, fair market rent, poverty level income

To avoid data leakage issues, the features corresponding to cost measures are not fed into the machine learning models. The table below lists the features used to predict the monthly housing cost.

<table style="width:50%">
  <tr>
    <th>Feature Name</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>AGE</td>
    <td>Age of head of household</td>
  </tr>
  <tr>
    <td>BEDRMS</td>
    <td>Number of bedrooms in unit</td>
  </tr>
  <tr>
    <td>FMR</td>
    <td>Fair market rent</td>
  </tr>
  <tr>
    <td>INCRELAMIPCT</td>
    <td>Household income relative to area median income (percent)</td>
  </tr>
  <tr>
    <td>IPOV</td>
    <td>Poverty income</td>
  </tr>
  <tr>
    <td>LMED</td>
    <td>Area median income (average)</td>
  </tr>
  <tr>
    <td>NUNITS</td>
    <td>Number of units in building</td>
  </tr>
  <tr>
    <td>PER</td>
    <td>Number of persons in household</td>
  </tr>
  <tr>
    <td>ROOMS</td>
    <td>Number of rooms in unit</td>
  </tr>
  <tr>
    <td>VALUE</td>
    <td>Current market value of unit</td>
  </tr>
  <tr>
    <td>REGION</td>
    <td>Census region</td>
  </tr>
  <tr>
    <td>YEAR</td>
    <td>Year of housing survey</td>
  </tr>
  <tr>
    <td>FMTBUILT</td>
    <td>Year unit was built</td>
  </tr>
  <tr>
    <td>FMTASSISTED</td>
    <td>Assisted housing</td>
  </tr>
  <tr>
    <td>FMTSTRUCTURETYPE</td>
    <td>Structure type</td>
  </tr>
  <tr>
    <td>FMTMETRO</td>
    <td>Central city/suburban status</td>
  </tr>
  <tr>
    <td>FMTZADEQ</td>
    <td>Adequacy of unit</td>
  </tr>
</table> 

The data files provide more features which are not included in the following analysis. These discarded variables are related to either LMED or INCRELAMIPCT.

## MODELS

Two supervised learning algorithms are applied to predict the monthly housing cost (column name is ZSMHC in data files): ridge linear and random forest. The data is split into a test and training set. The training set is used to fit the model and the test data is used to calculate the model’s score. The table below lists the scores for the different models<sup><a href="#fn1" id="ref1">1</a></sup>:

<table style="width:30%">
  <tr>
    <th>Model</th>
    <th>Score</th>
  </tr>
  <tr>
    <td>Linear Ridge</td>
    <td>0.5</td>
  </tr>
  <tr>
    <td>Random Forest</td>
    <td>0.6</td>
  </tr>
</table>

### Ridge Linear Model

This model is applied due to its simplicity and easy interpretability of the output coefficients. At first, the hyperparameter alpha is tuned over the range from 0.01 to 100. The best value was found to be an alpha of 10. However, the score value was roughly the same across all values of alpha used (score was about 0.57). In order to compare the relative importance of the coefficients, the data was scaled to mean 0 and variance 1, and the train scaled data was fitted to a linear ridge instance with alpha set to 10. The corresponding coefficients for the scaled data are plotted below.

![coefficients scaled linear model]({{ site.baseurl }}/assets/images/coeffs_scaled_linear.png "coefficients scaled linear model")

### Random Forest
The next model used is the random forest. This is a popular model that can account for nonlinear effects in the data, unlike the ridge linear model. The training data is fed into an instance of a random forest model with default parameters. The score on the test data is around 0.57. Next the training data set is used for 3-fold cross validation, obtaining scores in the 0.56-0.57 range. The feature importance values are plotted below. The importance values add up to one. The higher a feature’s importance value, the more important that feature is.
It is to be noted that for the data comprised of the survey years 2009-2013, tuning was performed over the parameters max_depth, max_features, n_estimators over the values [3, 5, 7, None],  ['auto', 'sqrt', 'log2'], and [10, 100], respectively.<sup><a href="#fn2" id="ref2">2</a></sup> The best parameter combination turned out to be (max_depth = None, max_features = ‘auto’, n_estimators = 100) with best score of 0.541. However, due to constraints in computational resources, the default parameter combination (max_depth = None, max_features = ‘auto’, n_estimators = 10) was used on the full data set.

![random forest importance]({{ site.baseurl }}/assets/images/importance_rf.png "random forest importance")

### Support Vector Machine
Finally, a support vector machine (SVM) model is used to predict whether or not a housing unit monthly cost is in the top 10%. For this part, a new column was created indicating whether or not a housing unit is in the top 10% of monthly housing cost for a given survey year. This column becomes the variable that the support vector machine needs to predict. The results of this model will be presented in the next section. Again the training data is used to fit the model and the test data is used to quantify the prediction accuracy.

## DISCUSSION

In the table below, the top 5 most important features are listed for the ridge linear and random forest model. Both models agree that the housing unit market value (feature name VALUE) is an important factor in determining the monthly housing cost. For ridge linear, the 4 other important features features are measurements related to the median area income. For random forest, the 4 other important features have to do with the household’s income and the age of the head of the household.

<table style="width:50%">
  <tr>
    <th colspan="2">Ridge Linear</th>
    <th colspan="2">Random Forest</th>
  </tr>
  <tr>
    <td>Feature</td>
    <td>Coefficent</td>
    <td>Feature</td>
    <td>Importance</td>
  </tr>
  <tr>
    <td>GL50</td>
    <td>0.448</td>
    <td>VALUE</td>
    <td>0.469</td>
  </tr>
  <tr>
    <td>GL50</td>
    <td>0.448</td>
    <td>VALUE</td>
    <td>0.469</td>
  </tr>
</table> 

<hr>

<sup id="fn1">1. The score function used is the r-squared value. Other score functions are available in sci-kit learn. For r-squared, a score of 1 indicates a model that exactly predicts the actual values<a href="#ref1" title="Jump back to footnote 1 in the text.">↩</a></sup>

<sup id="fn2">2. See sci-kit learn RadomForestRegressor documentation for definition of these parameters<a href="#ref2" title="Jump back to footnote 2 in the text.">↩</a></sup>
