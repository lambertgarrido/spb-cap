{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(771870, 24)\n",
      "(771870, 20)\n",
      "(486785, 20)\n",
      "Index(['AGE', 'BEDRMS', 'FMR', 'INCRELAMIPCT', 'IPOV', 'LMED', 'NUNITS', 'PER',\n",
      "       'ROOMS', 'VALUE', 'ZSMHC', 'REGION', 'YEAR', 'FMTBUILT_'1960-1979'',\n",
      "       'FMTBUILT_'1980-1989'', 'FMTBUILT_'1990-1999'', 'FMTBUILT_'2000-2009'',\n",
      "       'FMTBUILT_'After 2010'', 'FMTBUILT_'not_defined'',\n",
      "       'FMTASSISTED_'0 Not Assisted'', 'FMTSTRUCTURETYPE_'2 2-4 units'',\n",
      "       'FMTSTRUCTURETYPE_'3 5-19 units'', 'FMTSTRUCTURETYPE_'4 20-49 units'',\n",
      "       'FMTSTRUCTURETYPE_'5 50+ units'', 'FMTSTRUCTURETYPE_'6 Mobile Home'',\n",
      "       'FMTMETRO_'Central City'', 'FMTZADEQ_'2 Moderately Inadequ'',\n",
      "       'FMTZADEQ_'3 Severely Indadequa''],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import gc\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "#df_13 = pd.read_csv('13_clean.csv')\n",
    "#df_13.head()\n",
    "\n",
    "years = ['85', '87', '89', '91', '93', '95', '97', '99', '01', '03', '05', '07', '09', '11', '13']\n",
    "years_num = [1985, 1987, 1989, 1991, 1993, 1995, 1997, 1999, 2001, 2003, 2005, 2007, 2009, 2011, 2013 ]\n",
    "\n",
    "\n",
    "def combineDataFrame(years, years_num):\n",
    "    \n",
    "    df_allYears = pd.DataFrame()\n",
    "    \n",
    "    for year, i in zip(years, years_num):\n",
    "        df = pd.read_csv(year + '_clean.csv')\n",
    "        df['YEAR'] = i\n",
    "        df_allYears = df_allYears.append(df)\n",
    "    \n",
    "    return df_allYears\n",
    "    \n",
    "df_allYears = combineDataFrame(years, years_num)\n",
    "\n",
    "#Keep only LMED from above set since 'ABL50', 'ABL80', 'ABLMED', 'GL50', 'GL80', 'GLMED', 'L50' are correlated\n",
    "cols = ['ABL50', 'ABL80', 'ABLMED', 'GL50', 'GL80', 'GLMED', 'L50']\n",
    "df_allYears.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Keep only 'INCRELAMIPCT' from above set since 'ZINC2', 'TOTSAL' are correlated\n",
    "cols = ['ZINC2', 'TOTSAL']\n",
    "df_allYears.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "#choose columns that are independent, e.g. COSTMED, COSTMEDRELAMITPCT, FMTCOSTMEDRELAMIPCT \n",
    "#show the same data in different format; ditto for FMTINCRELAMICAT and INCRELAMIPCT\n",
    "# drop CONTROL as well\n",
    "cols = ['CONTROL', 'COSTMED', 'FMTCOSTMEDRELAMICAT', 'FMTINCRELAMICAT']\n",
    "df_allYears.drop(cols, axis=1, inplace=True)\n",
    "print(df_allYears.shape)\n",
    "\n",
    "#removing columns related to cost since these are related to target variable ZSMHC (monthly housing cost)\n",
    "cols = ['COSTMEDRELAMIPCT', 'BURDEN', 'OTHERCOST', 'UTILITY']\n",
    "df_allYears.drop(cols, axis=1, inplace=True)\n",
    "print(df_allYears.shape)\n",
    "\n",
    "#drop na values\n",
    "df_allYears = df_allYears.dropna()\n",
    "print(df_allYears.shape)\n",
    "\n",
    "#remove values of FMTMETRO set to 9;\n",
    "df_allYears = df_allYears.loc[~df_allYears['FMTMETRO'].str.contains('9', regex=False)]\n",
    "\n",
    "\n",
    "#drop FMTSTATUS - earlier generated ill-defined matrix warning for ridge regression;\n",
    "#values for this column is constanct for several years\n",
    "df_allYears.drop('FMTSTATUS', axis=1, inplace=True)\n",
    "\n",
    "#converting REGION from int type to string type\n",
    "df_allYears['REGION'].apply(str)\n",
    "\n",
    "#convert categorical variables to indicator variables\n",
    "df_allYears = pd.get_dummies(df_allYears, drop_first=True)\n",
    "\n",
    "print(df_allYears.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [1985, 1987, 1989, 1991, 1993, 1995, 1997, 1999, 2001, 2003, 2005, 2007, 2009, 2011, 2013]\n",
    "\n",
    "quantiles = {}\n",
    "for year in years:\n",
    "    quantiles[year] = df_allYears.loc[df_allYears['YEAR'] == year, 'ZSMHC'].quantile(0.9)\n",
    "\n",
    "df_allYears['QUANTILE'] = df_allYears['YEAR']\n",
    "df_allYears.replace({'QUANTILE':quantiles})\n",
    "\n",
    "df_allYears['IS_TOP_10'] = df_allYears['ZSMHC'] >= df_allYears['QUANTILE']\n",
    "\n",
    "df_allYears['IS_TOP_10'] = df_allYears['IS_TOP_10'].apply(int)\n",
    "\n",
    "df_allYears = df_allYears.drop(['QUANTILE', 'ZSMHC'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score =  0.9251833204145888\n"
     ]
    }
   ],
   "source": [
    "X = df_allYears.drop(['IS_TOP_10'], axis=1).values\n",
    "\n",
    "y = df_allYears['IS_TOP_10'].values\n",
    "\n",
    "del df_allYears\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_scaled = scale(X_train)\n",
    "#y_train_scaled = scale(y_train)\n",
    "\n",
    "X_test_scaled = scale(X_test)\n",
    "#y_test_scaled = scale(y_test)\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "score = clf.score(X_test_scaled, y_test)\n",
    "\n",
    "print('score = ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df_toKeep.drop(['IS_TOP_10'], axis=1).columns)\n",
    "year_array = X_test[:,cols.index('YEAR')]\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "#accuracy is sum of true positive and true negatives divide by total number of observations\n",
    "#precision is true positive divided by total predicted positive values\n",
    "#recall is true positive divided by total actual positive values\n",
    "\n",
    "for year in years:\n",
    "    y_test_year = y_test[year_array == year]\n",
    "    y_pred_year = y_pred[year_array == year]\n",
    "    #print(np.sum(year_array == year))\n",
    "    accuracies.append(metrics.accuracy_score(y_test_year, y_pred_year))\n",
    "    precisions.append(metrics.precision_score(y_test_year, y_pred_year))\n",
    "    recalls.append(metrics.recall_score(y_test_year, y_pred_year))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(years, accuracies, label='accuracy', marker = '+')\n",
    "plt.plot(years, precisions, label='precision', marker = 'o')\n",
    "plt.plot(years, recalls, label='recall', marker = 'x')\n",
    "plt.xticks(years, years, rotation=60)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [1985, 1987]:\n",
    "    y_test_year = y_test[year_array == year]\n",
    "    y_pred_year = y_pred[year_array == year]\n",
    "    print(metrics.confusion_matrix(y_test_year, y_pred_year))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the second column of confusion matrix consists of zeroes, the model does not predict any positive values for years 1985 and 1987. Therfore the precision is undefined and set to zero in the plot above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
